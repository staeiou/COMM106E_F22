{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0294d-ff24-4970-a125-9d29584fdc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f78df7-b5ea-4184-8923-b6346b0c1bd8",
   "metadata": {},
   "source": [
    "## Combining multiple data files (which all must have the same columns)\n",
    "\n",
    "We can use `glob` to select all files in the data directory. Here the `*` character stands for 'match anything' (and not multiplication, as it is used elsewhere). This line says to get all the files ending in `.csv` that are in any subdirectory of `data/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a95b1-ba73-43c5-b612-b41cc8e4ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob.glob(\"data/*/*.csv\")\n",
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d0b93c-ea3e-4fc1-9c73-122718b85587",
   "metadata": {},
   "source": [
    "## Combining the files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4ab02-f703-42eb-b1c2-837528b0af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in data_files:\n",
    "    data_temp = pd.read_csv(file)\n",
    "    all_files.append(data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edfb12-3654-4896-86d6-2dab94f7db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(all_files)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbba01b-5fae-4123-b0cb-5270911dcff4",
   "metadata": {},
   "source": [
    "We also want to rename those columns into things that remove the newlines (or `\\n`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f442d161-5fbf-4b7b-a976-220e6bfc90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971cf2f-9fe7-4e9b-84a2-f0d542499f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['year', 'location', 'first_name', 'last_name', 'title', 'total_pay', 'regular_pay', 'overtime_pay', 'other_pay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f81c7-b583-4d03-b380-a1025537ffa6",
   "metadata": {},
   "source": [
    "## Filter to 2021 data\n",
    "\n",
    "Because 2021 is a number, we don't need to put single quotes around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a593c4f-fac9-47f7-adb8-4682b4d2ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021 = data.query(\"year == 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123384f8-f3fb-4cf5-a867-df17322647d7",
   "metadata": {},
   "source": [
    "## Counting the number of workers in each location:\n",
    "We will do a `groupby` with the location column. After the groupby function, you should usually specify which column you want to work with. We want to count the number of workers in each location, so it doesn't matter which column you want to work with here. It will matter when we do mean, median, or total salary later, we have to specify which salary column we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607a3da-ce51-4432-9a24-7787673e8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021.groupby('location')['year'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef28f68-98ff-482e-b4b1-af700f44fb70",
   "metadata": {},
   "source": [
    "We can sort the list smallest to largest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a26b84-e604-41c7-81e2-9a06cd443d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021.groupby('location')['year'].count().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5823c9-7b28-4771-b5bb-3d8df8882361",
   "metadata": {},
   "source": [
    "We can visualize a horizontal bar graph by adding `.plot(kind='barh')` to the sorted table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced0c22-555a-443f-8623-3ef8c37adf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021.groupby('location')['year'].count().sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0bc31-842c-4f92-9871-bae0e7a274d7",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "## Classifying titles\n",
    "One problem is that there are many different specialized titles, and the payroll system doesn't make it easy to tell them apart. At UCSD we have [this site](http://hr.ucsd.edu/tpp/) which you can use to lookup payroll titles and see a description.\n",
    "\n",
    "We will create a new function to classify these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5d1c49-bc90-469d-9325-c7a41ee0756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_title(text):\n",
    "    text = str(text).upper()\n",
    "    \n",
    "    if \"POSTDOC\" in text:\n",
    "        return \"POSTDOC\"\n",
    "    elif \"GSHIP\" in text or \"GSR\" in text:\n",
    "        return \"GRAD\"\n",
    "    elif \"LECT\" in text or \"TEACHER\" in text:\n",
    "        return \"LECTURER\"\n",
    "    elif \"DEAN\" in text and \"ASST\" not in text and \"AST\" not in text:\n",
    "        return \"EXEC\"\n",
    "    elif \"VC\" in text and \"ASST\" not in text and \"AST\" not in text and 'SVC' not in text:\n",
    "        return \"EXEC\"\n",
    "    elif \"CHAN\" in text and \"ASST\" not in text and \"AST\" not in text:\n",
    "        return \"EXEC\"\n",
    "    elif \"CMO MED CTR\" in text:\n",
    "        return \"EXEC\"\n",
    "    elif \"PROF\" in text:\n",
    "        return \"PROF\"\n",
    "    elif \"STDT\" in text or \"MGR\" in text or \"AST\" in text or \"SRA\" in text or \"ADMIN\" in text or \"SPEC\" in text or \"HR\" in text or \"ANL\" in text:\n",
    "        return \"ADMIN\"\n",
    "    elif \"NURSE\" in text or \"PHYS\" in text or \"PAT\" in text or \"MED C\" in text or \"CLIN\" in text or \"PHARM\" in text:\n",
    "        return \"MEDICAL-OTHER\"\n",
    "    else:\n",
    "        return \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242b7fd-ced8-408a-99c1-52a10cf10732",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_title(\"HR GENERALIST 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead2b06-02e5-46ec-b9df-f1f63acf15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_title(\"TEACHG ASST-GSHIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64904843-7de6-4ead-a599-a3f5508cc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_title(\"ASSOC DEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a26e58-0741-4955-9a7c-70ee4a902935",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_title(\"AST TO DEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41880f5c-f41f-4f68-9925-5b15c8e6b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_title(\"HS ASST CLIN PROF-HCOMP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aefaad5-caf2-4914-a3f5-2b88d1ee6b20",
   "metadata": {},
   "source": [
    "### Using `apply` to classify all titles in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f0ca34-ac3c-4f1f-a4ea-ee4101a87a3f",
   "metadata": {},
   "source": [
    "We want to create a new column called `title_class`. This is where we will save the results of applying that function to the `title` column in our original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc14a17-9e2e-4672-bc34-1c33ef826b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_class'] = data['title'].apply(classify_title)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6c4f2-7662-4a20-9da0-65303a35a466",
   "metadata": {},
   "source": [
    "## Removing those whose total pay for a year is less than $15,000\n",
    "\n",
    "One big problem is that most people do not join or leave the university on Jan 1st. Most people start in the Fall and end in the Spring, meaning that there are lots of rows from first-year or last-year workers. Because we are interested in what the university is paying workers for a full year, a more robust way to do this is to remove all rows for people making under \\\\$15,000 a year, the minimum salary for someone working 50% time over 3 quarters. Someone working 30 hours a week at \\\\$15 an hour for a year would be above this and would be included. Someone who recieves $30,000 a year, but is just paid for one or two quarters would not be included.\n",
    "\n",
    "One problem with this is that it easily filters out the grad students, most of whose salaries for a full year are less than \\\\$30,000. However, it does not filter out part-year salaries for those who make more than this. The executive who makes \\\\$600,000 who joins on Dec 1st of a year would have a reported income of \\\\$50,000 for that year, which would not be filtered out. This likely means that we are slightly underestimating the income of those who make more than \\\\$30,000 a year. \n",
    "\n",
    "Data cleaning is full of political and value choices!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e05b5b-d92b-4669-9cdf-1150561c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query(\"title_class == 'GRAD'\")['total_pay'].hist(bins=100, figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31edfb1-8f18-4bf6-8d06-7633bfe42097",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.query(\"total_pay > 15000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdac662-f544-4c6b-a144-80258804731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021 = data_cleaned.query(\"year == 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28239b4c-5066-4042-8369-6bc504df3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021['title_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070e337-2024-4a8b-a116-825cc326d2e7",
   "metadata": {},
   "source": [
    "We are also going to save a version of the 2021 dataset that is not filtered out, because later we will look at the total money spent on the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bfd150-c0cf-4710-bb81-3c302ca09dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021_all = data.query(\"year == 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55960cd-952f-4a7f-98f2-84b29c75f357",
   "metadata": {},
   "source": [
    "## Pivot tables\n",
    "\n",
    "For a pivot table, you give it a dataset and tell it what a summarized table should look like. You specify the rows (or index), the columns, the values, and how you want to summarize the data. So we want our rows/index to be the title_class, the columns to be the location, and the values to be total_pay. You should also specify the `aggfunc` or aggregation function: should it give you the mean (average), median, sum (total) of all of those values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4d87d-e5ed-4c06-8d07-293fd7d28af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_median_total_by_loc = pd.pivot_table(data_2021, index='title_class', columns='location', values='total_pay', aggfunc='median')\n",
    "pivot_median_total_by_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246ac26-44bd-4100-8cd0-94a2682c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_median_total_by_loc.plot(kind='barh', figsize=(5,10), xlabel=\"Median total pay in 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb2c0f3-9b46-45f3-8531-e6c9747cabfd",
   "metadata": {},
   "source": [
    "We can also change the `aggfunc` to `sum` to add up all the entries in each of our pivot table's rows and columns, instead of finding the median. But first, remember how we removed everyone making less than $15k? We want to put them back, which is why we didn't overwrite the `data` variable with our original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c205d50-afd6-433a-9ba5-00d33bb98b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021_all = data.query(\"year == 2021\")\n",
    "data_2021_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b82fdb-8f73-4a1e-8827-d2d8215eeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_sum_total_by_loc = pd.pivot_table(data_2021_all, index='title_class', columns='location', values='total_pay', aggfunc='sum')\n",
    "pivot_sum_total_by_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6d5c9-df7b-49cc-a7d6-b823af141107",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_sum_total_by_loc.plot(kind='barh', figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86835eb-955d-422d-92ac-e5cfdc4ff58d",
   "metadata": {},
   "source": [
    "We can stack the bar graph to make this easier to visualize the total UC spending for each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170efc9c-80bc-447e-b568-36568d3ef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_sum_total_by_loc.plot(kind='barh', figsize=(9,9), stacked=True, xlabel=\"Billions of dollars spent in 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7687f-ee1a-40f0-a320-82f9defc6dd8",
   "metadata": {},
   "source": [
    "Instead of a pivot table, a `groupby` works if you just want to aggregate across one category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554dfc5f-6a5e-4e97-85cd-c46a1f69d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021_all.groupby('title_class')['total_pay'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b489dcd-75d0-45d0-bc14-75940d864e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021_all.groupby('title_class')['total_pay'].sum().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2925c2-63c4-423a-9554-88349fca08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.min_rows', 30)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb1ef57-dede-464f-ae72-0a1453fd4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021_all.query(\"title_class == 'EXEC'\").sort_values('total_pay', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c629810-f4ca-46b1-98f0-0ab6caffe8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
